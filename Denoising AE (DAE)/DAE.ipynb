{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from __future__ import division, print_function, absolute_import\n",
    "\n",
    "\n",
    "#for plotting\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#importing mnist data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#setting parameters for learning\n",
    "lr = 0.01\n",
    "num_epochs = 30\n",
    "batch_size = 256\n",
    "display_step = 2\n",
    "\n",
    "#for plotting\n",
    "examples_to_show = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#setting parameters for network layers\n",
    "n_input = 784 #28x28\n",
    "n_hidden_1 = 256\n",
    "n_hidden_2 = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#setting up placeholder input and output\n",
    "X = tf.placeholder(\"float\", [None, n_input])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#setting up layer sizes\n",
    "\n",
    "weights = {\n",
    "    'encoder_1': tf.Variable(tf.random_normal([n_input, n_hidden_1])),\n",
    "    'encoder_2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "    'decoder_1': tf.Variable(tf.random_normal([n_hidden_2, n_hidden_1])),\n",
    "    'decoder_2': tf.Variable(tf.random_normal([n_hidden_1, n_input]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'encoder_1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'encoder_2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'decoder_1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'decoder_2': tf.Variable(tf.random_normal([n_input]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#setting up the network structure\n",
    "\n",
    "def encoder(x):\n",
    "    activation_1 = tf.nn.sigmoid(tf.matmul(x, weights['encoder_1']) + biases['encoder_1'])\n",
    "    activation_2 = tf.nn.sigmoid(tf.matmul(activation_1, weights['encoder_2']) + biases['encoder_2'])\n",
    "    return activation_2\n",
    "\n",
    "def decoder(x):\n",
    "    activation_1 = tf.nn.sigmoid(tf.matmul(x, weights['decoder_1']) + biases['decoder_1'])\n",
    "    activation_2 = tf.nn.sigmoid(tf.matmul(activation_1, weights['decoder_2']) + biases['decoder_2'])\n",
    "    return activation_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#defining output from the network and supervisory labels (input data itself)\n",
    "decoded = decoder(encoder(X))\n",
    "actual = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#defining loss and optimizer\n",
    "cost = tf.reduce_mean(tf.pow((actual - decoded), 2)) #L2 norm\n",
    "optimizer = tf.train.RMSPropOptimizer(lr).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#initializing all the variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#running the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "    \n",
    "    #training\n",
    "    for epoch in range(num_epochs):\n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            \n",
    "            #add noise to x (gaussian)\n",
    "            noise = tf.random_normal(shape=[batch_size, 784]).eval()\n",
    "            batch_xs = batch_xs + (noise)/5\n",
    "            \n",
    "            #optimizing w/ backprop and running cost op (for loss)\n",
    "            _, c = sess.run([optimizer, cost], feed_dict={X: batch_xs})\n",
    "        \n",
    "        #showing logs per epoch\n",
    "        if (epoch % display_step) == 0:\n",
    "            print('Epoch=', epoch+1, ' ; cost=', c)\n",
    "            \n",
    "    print(\"Optimization Done\")\n",
    "    \n",
    "    \n",
    "    #running net on test set\n",
    "    encode_decode = sess.run(decoded, feed_dict={X:mnist.test.images[:examples_to_show]})\n",
    "    \n",
    "    #plot input images vs output images\n",
    "    f, a = plt.subplots(2, 10, figsize=(10, 2))\n",
    "    for i in range(examples_to_show):\n",
    "        a[0][i].imshow(np.reshape(mnist.test.images[i], (28, 28)))\n",
    "        a[1][i].imshow(np.reshape(encode_decode[i], (28, 28)))\n",
    "        \n",
    "    f.show()\n",
    "    plt.draw()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
