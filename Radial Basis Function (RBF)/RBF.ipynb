{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#RBF Network on MNIST (FFN with RBF activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.examples.tutorials.mnist.input_data as input_data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#for rbf\n",
    "from scipy import *\n",
    "from scipy.linalg import norm, pinv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#importing mnist dataset as a tf dataset\n",
    "mnist = input_data.read_data_sets(\"../Data/MNIST/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#fixing some parameters\n",
    "learning_rate = 0.1\n",
    "training_epochs = 50\n",
    "batch_size = 100\n",
    "display_step = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#defining input tensor (28x28 = 784)\n",
    "x = tf.placeholder(\"float\", shape=[None, 784])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#defining final layer tensor\n",
    "y = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Gathering evidence\n",
    "\n",
    "#defining weigths and biases\n",
    "W  = tf.Variable(tf.zeros([784,10]))\n",
    "b = tf.Variable(tf.zeros([10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#gaussian rbf is simpty squared distance from point in n dimensions. We abstract dimensionality to tensor operations in the numerator.\n",
    "def rbf(x):\n",
    "    return tf.exp(-8 *((x)**2)) #letting origin of RBF be 0, beta = 8, and radius be 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#computing class probabilities from evidence using softmax:\n",
    "activation = tf.nn.softmax(tf.matmul(rbf(x),W) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_entropy = y * tf.log(activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#cost function will be calculating the cross-entropy's error (C=−1/n∑x[ylnσ+(1−y)ln(1−σ)], where σ := sigmoid)\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(cross_entropy, reduction_indices=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#I now have a model, but to train, it needs a learning algorithm\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#defining arrays used for plotting cost function's convergence\n",
    "avg_set = []\n",
    "epoch_set=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###--------------All variables have now been written------------------###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#defining the tf object that will be used to initialize all your variables at once\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    #running the session using context manager\n",
    "    sess.run(init)\n",
    "    \n",
    "    #iterating over each epoch\n",
    "    for epoch in range(int(training_epochs)):\n",
    "        avg_cost = 0\n",
    "        total_batch = int(mnist.train.num_examples/batch_size) #number of batches\n",
    "\n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys= mnist.train.next_batch(batch_size) #grab a batch\n",
    "\n",
    "            #fitting the model, using our defined optimizer and passing one batch to the placeholders\n",
    "            sess.run(optimizer, feed_dict={x: batch_xs, y: batch_ys})\n",
    "\n",
    "            #evaluating cost passing one batch into the placeholders\n",
    "            avg_cost += sess.run(cost, feed_dict={x: batch_xs, y:batch_ys})/total_batch\n",
    "            \n",
    "        #printing epoch and cost each epoch\n",
    "        if epoch % display_step == 0:\n",
    "            print(\"Epoch=\", epoch, \"; cost=\", \"{0:.4f}\".format(avg_cost))\n",
    "    \n",
    "        #saving costs each epoch for plotting\n",
    "        epoch_set = np.append(epoch_set, epoch)\n",
    "        avg_set = np.append(avg_set, avg_cost)\n",
    "    \n",
    "    #----DONE TRAINING----\n",
    "    print(\"Training finished!\")\n",
    "            \n",
    "    #finding accuracies (correct if highest probability in output is at an index equal to input digit's real number value)\n",
    "    correct_prediction = tf.equal(tf.argmax(activation, 1), tf.argmax(y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    \n",
    "    print(\"Model accuracy: \", \"{0:.4f}\".format(accuracy.eval({x: mnist.test.images, y: mnist.test.labels})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plot cost function convergence as network trains\n",
    "plt.plot(epoch_set, avg_set)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
