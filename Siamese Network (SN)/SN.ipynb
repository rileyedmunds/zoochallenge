{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Siamese Network on MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#imports\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import tensorflow as tf \n",
    "from tensorflow.examples.tutorials.mnist import input_data # for data\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../Data/MNIST/train-images-idx3-ubyte.gz\n",
      "Extracting ../Data/MNIST/train-labels-idx1-ubyte.gz\n",
      "Extracting ../Data/MNIST/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../Data/MNIST/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "#importing mnist dataset as a tf dataset\n",
    "mnist = input_data.read_data_sets(\"../Data/MNIST/\", one_hot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#functions to set up the model\n",
    "def twin_net(x):\n",
    "    '''set up one instance of twin network\n",
    "                1024 -> 1024 -> 2       '''\n",
    "    #layer 1\n",
    "    fc1 = make_fc(x, 1024, \"fc1\")\n",
    "    activ1 = tf.nn.relu(fc1)\n",
    "    #layer2\n",
    "    fc2 = make_fc(activ1, 1024, \"fc2\")\n",
    "    activ2 = tf.nn.relu(fc2)\n",
    "     #layer3\n",
    "    fc3 = make_fc(activ2, 2, \"fc3\")\n",
    "    \n",
    "    return fc3\n",
    "\n",
    "#create an affine layer\n",
    "def make_fc(bottom, n_weight, name):\n",
    "    '''return speccified fc layer w/ correct sizing, normal weights, constant bias'''\n",
    "    prev_shape = bottom.get_shape()[1]\n",
    "    W = tf.get_variable(name=name+'_W', dtype=tf.float32, shape=[prev_shape, n_weight], initializer=tf.truncated_normal_initializer(stddev=0.01))\n",
    "    b = tf.get_variable(name=name+'_b', dtype=tf.float32, initializer=tf.constant(value=0.01, shape=[n_weight], dtype=tf.float32))\n",
    "    fc = tf.nn.bias_add(tf.matmul(bottom, W), b)\n",
    "    \n",
    "    return fc\n",
    "    \n",
    "def contrastive_loss():\n",
    "    '''spring-like loss function comparing output from twin nets\n",
    "    --> on learned manifold, similar inputs map to nearby points'''\n",
    "    #pos loss: (1/2N) * SUM[1toN](y)* d^2 [ <-- summation is eucd^2]\n",
    "    labels_t = y_  #bool: do labels match \n",
    "    eucd2 = tf.reduce_sum(tf.pow(tf.sub(o1, o2), 2), 1) #squared eucd between nets\n",
    "        #loss:\n",
    "        \n",
    "    print(labels_t)\n",
    "    print('labels, then eucd2')\n",
    "    print(eucd2)\n",
    "    \n",
    "    pos = tf.mul(labels_t, eucd2)\n",
    "\n",
    "    #neg loss: (1-y)*max(margin-d, 0)^2\n",
    "    labels_f = tf.sub(1., y_) #1-y\n",
    "    eucd = tf.sqrt(eucd2+1e-6)\n",
    "    margin = 5.0\n",
    "    C = tf.constant(value=margin)\n",
    "        #loss:\n",
    "    neg = tf.mul(labels_f, tf.pow(tf.maximum(tf.sub(C, eucd), 0), 2))\n",
    "    \n",
    "    #full loss:\n",
    "    loss = tf.reduce_mean(tf.add(pos, neg))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Placeholder_2:0\", shape=(?,), dtype=float32)\n",
      "labels, then eucd2\n",
      "Tensor(\"Sum:0\", shape=(?,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#set up the model graph structure (connect nets)\n",
    "'''sets up entire siamese net (including twin nets and loss)'''\n",
    "x1 = tf.placeholder(tf.float32, [None, 784])\n",
    "x2 = tf.placeholder(tf.float32, [None, 784])\n",
    "\n",
    "with tf.variable_scope(\"siamese\") as scope:\n",
    "    o1 = twin_net(x1)\n",
    "    scope.reuse_variables()\n",
    "    o2 = twin_net(x2)\n",
    "\n",
    "y_ = tf.placeholder(tf.float32, shape=[None])\n",
    "loss = contrastive_loss()\n",
    "train_step = tf.train.AdamOptimizer(learning_rate=0.01).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:  0  loss:  22.029\n",
      "step:  10  loss:  8.10551\n",
      "step:  20  loss:  2.61952\n",
      "step:  30  loss:  2.61668\n",
      "step:  40  loss:  2.59073\n",
      "step:  50  loss:  3.90316\n",
      "step:  60  loss:  2.71831\n",
      "step:  70  loss:  1.88482\n",
      "step:  80  loss:  1.99286\n",
      "step:  90  loss:  3.55095\n",
      "step:  100  loss:  1.54913\n",
      "step:  110  loss:  3.07055\n",
      "step:  120  loss:  1.97322\n",
      "step:  130  loss:  6.01779\n",
      "step:  140  loss:  1.49061\n",
      "step:  150  loss:  1.81153\n",
      "step:  160  loss:  2.42218\n",
      "step:  170  loss:  2.11591\n",
      "step:  180  loss:  2.35878\n",
      "step:  190  loss:  3.22625\n",
      "step:  200  loss:  1.7571\n",
      "step:  210  loss:  1.99928\n",
      "step:  220  loss:  3.22604\n",
      "step:  230  loss:  2.15497\n",
      "step:  240  loss:  1.97825\n",
      "step:  250  loss:  1.72006\n",
      "step:  260  loss:  1.59874\n",
      "step:  270  loss:  1.51805\n",
      "step:  280  loss:  1.88649\n",
      "step:  290  loss:  1.69565\n",
      "step:  300  loss:  2.02736\n",
      "step:  310  loss:  1.77043\n",
      "step:  320  loss:  1.80751\n",
      "step:  330  loss:  1.21554\n",
      "step:  340  loss:  1.60711\n",
      "step:  350  loss:  1.02781\n",
      "step:  360  loss:  1.36096\n",
      "step:  370  loss:  1.16886\n",
      "step:  380  loss:  1.03445\n",
      "step:  390  loss:  2.41064\n",
      "step:  400  loss:  2.34089\n",
      "step:  410  loss:  1.54827\n",
      "step:  420  loss:  1.89516\n",
      "step:  430  loss:  1.73368\n",
      "step:  440  loss:  2.35072\n",
      "step:  450  loss:  2.06293\n",
      "step:  460  loss:  1.85422\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-0e4b9002bf84>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0mx1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch_x1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                 \u001b[0mx2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch_x2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                 y_:batch_y})\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m#printing intermediate results:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/rileyedmunds/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 766\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    767\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/rileyedmunds/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    962\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 964\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    965\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/rileyedmunds/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1014\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1015\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Users/rileyedmunds/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1019\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/rileyedmunds/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1001\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1002\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1003\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1004\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#execution of graph\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    #run model:\n",
    "    for it in range(10000):\n",
    "        batch_x1, batch_y1 = mnist.train.next_batch(128) #net 1\n",
    "        batch_x2, batch_y2 = mnist.train.next_batch(128) #net 2\n",
    "        batch_y = (batch_y1 == batch_y2).astype('float') #comparison for contrastive loss\n",
    "              \n",
    "        _, loss_v = sess.run([train_step, loss], feed_dict ={\n",
    "                x1:batch_x1, \n",
    "                x2:batch_x2, \n",
    "                y_:batch_y})\n",
    "    \n",
    "        #printing intermediate results:\n",
    "        if (it % 10 == 0): \n",
    "            print(\"step: \", it, \" loss: \", loss_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
